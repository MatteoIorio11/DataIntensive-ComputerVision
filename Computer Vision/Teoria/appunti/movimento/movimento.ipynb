{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import va\n",
    "from ipywidgets import interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "video = cv.VideoCapture(\"./simpsons abbey road.mp4\")\n",
    "prev = None\n",
    "fm = []\n",
    "thr = 50\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        # No more frames\n",
    "        break\n",
    "    f = cv.cvtColor(frame, cv.COLOR_BGR2GRAY).astype(np.uint16)\n",
    "    if prev is not None:\n",
    "        mask = np.zeros_like(f)\n",
    "        mask[np.abs(f - prev) > thr] = 255\n",
    "        fm.append((frame, mask))\n",
    "    prev = f\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86e8890617684ee3a95a163719aee274",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=241), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(i=(0,len(fm)-1))\n",
    "def frameVision(i=0):\n",
    "    va.show(fm[i][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mog = cv.createBackgroundSubtractorMOG2(detectShadows=False)\n",
    "\n",
    "video = cv.VideoCapture(\"./simpsons abbey road.mp4\")\n",
    "fm = []\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    f = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    mask = mog.apply(f)\n",
    "    fm.append((frame, mask))\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3087508ca9204ca9bdcfa1578903c235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=242), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(i=(0,len(fm)-1))\n",
    "def frameVisionMOG(i=0):\n",
    "    va.show(fm[i][1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improve the FRAME\n",
    "1. Resize del frame in modo da mantenere il focus solamente sull'oggetto in movimento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_SF = 2.0\n",
    "\n",
    "video = cv.VideoCapture(\"./simpsons abbey road.mp4\")\n",
    "fm1 = []\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    f = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    mask = mog.apply(cv.resize(f, None, fx=1/MASK_SF, fy=1/MASK_SF))\n",
    "    n_mask = cv.resize(mask, None, fx=MASK_SF, fy=MASK_SF, interpolation=cv.INTER_NEAREST)\n",
    "    fm1.append((frame, mask))\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7afec518a640feb7b6cc4036f92caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=242), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(i=(0,len(fm1)-1))\n",
    "def frameVisionMOG2(i=0):\n",
    "    va.show(fm1[i][1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Utilizzo delle componenti connesse per eliminare tutte le componenti con area minore di una certa soglia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_SF = 2.0\n",
    "\n",
    "video = cv.VideoCapture(\"./simpsons abbey road.mp4\")\n",
    "fm2 = []\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    f = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    mask = mog.apply(cv.resize(f, None, fx=1/MASK_SF, fy=1/MASK_SF))\n",
    "    n, cc, stats, _ = cv.connectedComponentsWithStats(mask)\n",
    "    small = [i for i in range(1, n) if stats[i, cv.CC_STAT_AREA] < 70]\n",
    "    mask[np.isin(cc, small)] = 0\n",
    "    n_mask = cv.resize(mask, None, fx=MASK_SF, fy=MASK_SF, interpolation=cv.INTER_NEAREST)\n",
    "    fm2.append((frame, mask))\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46b93a8f28854efc90282e0022633a3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=242), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(i=(0,len(fm1)-1))\n",
    "def frameVisionMOG2(i=0):\n",
    "    va.show(fm2[i][1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Riempio i buchi all'interno delle componenti connesse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "MASK_SF = 2.0\n",
    "se = cv.getStructuringElement(cv.MORPH_ELLIPSE, (5, 5))\n",
    "video = cv.VideoCapture(\"./simpsons abbey road.mp4\")\n",
    "fm3 = []\n",
    "while True:\n",
    "    ret, frame = video.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    f = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    mask = mog.apply(cv.resize(f, None, fx=1/MASK_SF, fy=1/MASK_SF))\n",
    "    \n",
    "    mask = cv.morphologyEx(mask, cv.MORPH_CLOSE, se)\n",
    "    n, cc, stats, _ = cv.connectedComponentsWithStats(mask, connectivity=4)\n",
    "    small = [i for i in range(1, n) if stats[i, cv.CC_STAT_AREA] < 70]\n",
    "    mask[np.isin(cc, small)] = 0\n",
    "    \n",
    "    n, cc, stats, _ = cv.connectedComponentsWithStats(mask, connectivity=4)\n",
    "    holes = [i for i in range(1, n) if stats[i, cv.CC_STAT_AREA] < 2000]\n",
    "    mask[np.isin(cc, holes)] = 255\n",
    "    \n",
    "    \n",
    "    n_mask = cv.resize(mask, None, fx=MASK_SF, fy=MASK_SF, interpolation=cv.INTER_NEAREST)\n",
    "    fm3.append((frame, n_mask))\n",
    "video.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96a58caba41445acaebd01ed327db700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=242), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(i=(0,len(fm1)-1))\n",
    "def frameVisionMOG2(i=0):\n",
    "    va.show(fm3[i][1])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean SHIFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_crit= ( cv.TERM_CRITERIA_EPS | cv.TermCriteria_COUNT, 10, 1)\n",
    "MIN_ARE_IN_WND = 200\n",
    "MIN_AREA = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_window_hist(i, frame, stats, mask):\n",
    "    x, y = stats[i, cv.CC_STAT_LEFT], stats[i, cv.CC_STAT_TOP]\n",
    "    w, h = stats[i, cv.CC_STAT_WIDTH], stats[i, cv.CC_STAT_HEIGHT]\n",
    "    roi = cv.cvtColor(frame[y:y+h, x:x+w], cv.COLOR_BGR2GRAY)\n",
    "    hist = cv.calcHist(images=[roi], channels=[0], mask=mask[y:y+h, x:x+w], histSize=[256], ranges=[0, 255])\n",
    "    return (x, y, w, h), hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_window(frame, mask, hist, window):\n",
    "    gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    conf_map = cv.calcBackProject(images=[gray], channels=[0], hist=hist, ranges=[0, 255], scale=1)\n",
    "    conf_map[mask==0]=0\n",
    "    _, new_window = cv.meanShift(probImage=conf_map, window=window, criteria=term_crit)\n",
    "    return new_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracked_objects = []\n",
    "next_label = 1\n",
    "res_tracking = []\n",
    "\n",
    "for frame, mask in fm3[1:]:\n",
    "\n",
    "    n, cc, stats, _ = cv.connectedComponentsWithStats(mask)\n",
    "    cc_used, next_tracked_objects = set(), []\n",
    "    if n > 1:\n",
    "        #Non ho solo il background\n",
    "        for wnd, hist, label in tracked_objects:\n",
    "            x, y, w, h = get_new_window(frame, mask, hist, wnd)\n",
    "            cc_hist, _ = np.histogram(cc[y:y+h, x:x+w], n, (0, n))\n",
    "            index = np.argmax(cc_hist[1:])+1\n",
    "            if index not in cc_used and cc_hist[index] >= MIN_ARE_IN_WND:\n",
    "                wnd, hist = get_window_hist(index, frame, stats, mask) # Un nuovo oggetto viene trovato nell'immagine che non era gia stato etichettato\n",
    "                next_tracked_objects.append((wnd, hist, label))\n",
    "                cc_used.add(index)\n",
    "                \n",
    "        for i in range(1, n):\n",
    "            if (stats[i, cv.CC_STAT_AREA] >= MIN_AREA) and (i not in cc_used):\n",
    "                wnd, hist = get_window_hist(i, frame, stats, mask)\n",
    "                next_tracked_objects.append((wnd, hist, next_label))\n",
    "                next_label += 1\n",
    "        tracked_objects = next_tracked_objects\n",
    "        \n",
    "        res = frame.copy()\n",
    "        \n",
    "        for (x,y,w,h), hist, label in tracked_objects:\n",
    "            cv.rectangle(res, (x,y), (x+w, y+h), 255, 2)\n",
    "            cv.rectangle(res, (x, y-22), (x+w, y), 255, -1)\n",
    "            cv.putText(res, f\"{label}\", (x+5, y-5), cv.FONT_HERSHEY_PLAIN, 1, 0, 1)\n",
    "        \n",
    "        res_tracking.append(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f920ead361ad4cdab7b1b1f92cb4b06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=182), Output()), _dom_classes=('widget-interact'…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(i=(0,len(res_tracking)-1))\n",
    "def frameVisionMOG2(i=0):\n",
    "    va.show(res_tracking[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
